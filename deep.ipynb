{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deep.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJrk6FVJklcr",
        "outputId": "6b387cca-ea63-468e-e4b6-91f671175835"
      },
      "source": [
        "!git clone https://github.com/mozilla/DeepSpeech.git\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'DeepSpeech'...\n",
            "remote: Enumerating objects: 23874, done.\u001b[K\n",
            "remote: Counting objects: 100% (411/411), done.\u001b[K\n",
            "remote: Compressing objects: 100% (185/185), done.\u001b[K\n",
            "remote: Total 23874 (delta 231), reused 359 (delta 213), pack-reused 23463\u001b[K\n",
            "Receiving objects: 100% (23874/23874), 49.48 MiB | 19.73 MiB/s, done.\n",
            "Resolving deltas: 100% (16362/16362), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9ShEM-wLl9Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e394c842-7a17-46e6-d02c-57e0267cf12c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvWyROKI30Eo",
        "outputId": "d44fe81e-ab73-4906-ce6e-936eb4233974"
      },
      "source": [
        "!pip install --upgrade tensorflow"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: tensorflow in /usr/local/lib/python3.7/dist-packages (2.5.0)\n",
            "Requirement already satisfied, skipping upgrade: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.12.0)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.12.4)\n",
            "Requirement already satisfied, skipping upgrade: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: grpcio~=1.34.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.34.1)\n",
            "Requirement already satisfied, skipping upgrade: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.36.2)\n",
            "Requirement already satisfied, skipping upgrade: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied, skipping upgrade: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied, skipping upgrade: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied, skipping upgrade: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied, skipping upgrade: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.5.0.dev2021032900)\n",
            "Requirement already satisfied, skipping upgrade: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.9.2->tensorflow) (57.0.0)\n",
            "Requirement already satisfied, skipping upgrade: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (1.31.0)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (3.3.4)\n",
            "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (1.8.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (0.6.1)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (0.4.4)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (4.2.2)\n",
            "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (4.7.2)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (0.2.8)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow) (4.5.0)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2021.5.30)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (0.4.8)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.5->tensorflow) (3.4.1)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow) (3.1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-k8M6flcAo3",
        "outputId": "5aed3443-3bfd-458d-a28d-ca61b0d17162"
      },
      "source": [
        "!nvidia-smi\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAwbQAfbdMUt",
        "outputId": "8540ccfd-3f1b-4e37-8c9d-c4388adbe72a"
      },
      "source": [
        "%cd DeepSpeech\n",
        "\n",
        "!pip3 install --upgrade -e .\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/DeepSpeech\n",
            "Obtaining file:///content/DeepSpeech\n",
            "Requirement already satisfied, skipping upgrade: absl-py in /usr/local/lib/python3.7/dist-packages (from deepspeech-training==0.10.0a3) (0.12.0)\n",
            "Collecting attrdict\n",
            "  Downloading https://files.pythonhosted.org/packages/ef/97/28fe7e68bc7adfce67d4339756e85e9fcf3c6fd7f0c0781695352b70472c/attrdict-2.0.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: bs4 in /usr/local/lib/python3.7/dist-packages (from deepspeech-training==0.10.0a3) (0.0.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from deepspeech-training==0.10.0a3) (1.19.5)\n",
            "Collecting optuna\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/18/b49ca91cf592747e19f2d333c2a86cd7c81895b922a5a09adf6335471576/optuna-2.8.0-py3-none-any.whl (301kB)\n",
            "\u001b[K     |████████████████████████████████| 307kB 7.9MB/s \n",
            "\u001b[?25hCollecting opuslib==2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/1d/7f/6dd65372355c8fd27cff78deb4fa0f2a6948f72a851035fb64aba6041b9f/opuslib-2.0.0.tar.gz\n",
            "Requirement already satisfied, skipping upgrade: pandas in /usr/local/lib/python3.7/dist-packages (from deepspeech-training==0.10.0a3) (1.1.5)\n",
            "Requirement already satisfied, skipping upgrade: progressbar2 in /usr/local/lib/python3.7/dist-packages (from deepspeech-training==0.10.0a3) (3.38.0)\n",
            "Collecting pyogg>=0.6.14a1\n",
            "  Downloading https://files.pythonhosted.org/packages/1a/13/07358440dc3e94a71f3cd0f734e90b41392cc125de1571a99c4f8b594ccb/PyOgg-0.6.14a1.tar.gz\n",
            "Collecting pyxdg\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/13/de39ddf4f9f9cea0c7684cd54a50d79c97ea99c9f6aed798fd13d0bd4609/pyxdg-0.27-py2.py3-none-any.whl (49kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from deepspeech-training==0.10.0a3) (0.2.2)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/dist-packages (from deepspeech-training==0.10.0a3) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: semver in /usr/local/lib/python3.7/dist-packages (from deepspeech-training==0.10.0a3) (2.13.0)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from deepspeech-training==0.10.0a3) (1.15.0)\n",
            "Collecting sox\n",
            "  Downloading https://files.pythonhosted.org/packages/3f/67/1810e9a69956eb236967b7174c11fd8d8c2cdab051509286f72e6c7e147e/sox-1.4.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: soundfile in /usr/local/lib/python3.7/dist-packages (from deepspeech-training==0.10.0a3) (0.10.3.post1)\n",
            "Collecting ds_ctcdecoder==0.10.0-alpha.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4e/e3/c077861c3b1be431a3e7a11ac0f8fab9a29afd4dc24f3a786cdb2048ffb0/ds_ctcdecoder-0.10.0a3-cp37-cp37m-manylinux1_x86_64.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 35.9MB/s \n",
            "\u001b[?25hCollecting tensorflow==1.15.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/04/9f/18e031f52c46b4c63f6a6f064cd2dd85a2f730ca5dc44ef2f25375990dce/tensorflow-1.15.4-cp37-cp37m-manylinux2010_x86_64.whl (110.5MB)\n",
            "\u001b[K     |████████████████████████████████| 110.5MB 79kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from bs4->deepspeech-training==0.10.0a3) (4.6.3)\n",
            "Requirement already satisfied, skipping upgrade: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna->deepspeech-training==0.10.0a3) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna->deepspeech-training==0.10.0a3) (1.4.20)\n",
            "Collecting cmaes>=0.8.2\n",
            "  Downloading https://files.pythonhosted.org/packages/01/1f/43b01223a0366171f474320c6e966c39a11587287f098a5f09809b45e05f/cmaes-0.8.2-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna->deepspeech-training==0.10.0a3) (20.9)\n",
            "Collecting colorlog\n",
            "  Downloading https://files.pythonhosted.org/packages/32/e6/e9ddc6fa1104fda718338b341e4b3dc31cd8039ab29e52fc73b508515361/colorlog-5.0.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna->deepspeech-training==0.10.0a3) (4.41.1)\n",
            "Collecting cliff\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/11/aea1cacbd4cf8262809c4d6f95dcb3f2802594de1f51c5bd454d69bf15c5/cliff-3.8.0-py3-none-any.whl (80kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 5.3MB/s \n",
            "\u001b[?25hCollecting alembic\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/80/ef186e599a57d0e4cb78fc76e0bfc2e6953fa9716b2a5cf2de0117ed8eb5/alembic-1.6.5-py2.py3-none-any.whl (164kB)\n",
            "\u001b[K     |████████████████████████████████| 174kB 24.9MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->deepspeech-training==0.10.0a3) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->deepspeech-training==0.10.0a3) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: python-utils>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from progressbar2->deepspeech-training==0.10.0a3) (2.5.6)\n",
            "Requirement already satisfied, skipping upgrade: numba>=0.32 in /usr/local/lib/python3.7/dist-packages (from resampy>=0.2.2->deepspeech-training==0.10.0a3) (0.51.2)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->deepspeech-training==0.10.0a3) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->deepspeech-training==0.10.0a3) (2021.5.30)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->deepspeech-training==0.10.0a3) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->deepspeech-training==0.10.0a3) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile->deepspeech-training==0.10.0a3) (1.14.5)\n",
            "Collecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->deepspeech-training==0.10.0a3) (1.12.1)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 27.5MB/s \n",
            "\u001b[?25hCollecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->deepspeech-training==0.10.0a3) (0.8.1)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->deepspeech-training==0.10.0a3) (3.3.0)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->deepspeech-training==0.10.0a3) (1.34.1)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->deepspeech-training==0.10.0a3) (0.36.2)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->deepspeech-training==0.10.0a3) (0.2.0)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->deepspeech-training==0.10.0a3) (3.17.3)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 26.6MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->deepspeech-training==0.10.0a3) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.4->deepspeech-training==0.10.0a3) (1.1.2)\n",
            "Requirement already satisfied, skipping upgrade: greenlet!=0.4.17; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna->deepspeech-training==0.10.0a3) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna->deepspeech-training==0.10.0a3) (4.6.0)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna->deepspeech-training==0.10.0a3) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: PyYAML>=3.12 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna->deepspeech-training==0.10.0a3) (3.13)\n",
            "Collecting cmd2>=1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/44/ca/d407811641ec1d8bd8a38ee3165d73aa44776d7700436bd4d4a6606f2736/cmd2-2.1.2-py3-none-any.whl (141kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 41.9MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna->deepspeech-training==0.10.0a3) (2.1.0)\n",
            "Collecting stevedore>=2.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/49/b602307aeac3df3384ff1fcd05da9c0376c622a6c48bb5325f28ab165b57/stevedore-3.3.0-py3-none-any.whl (49kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 4.1MB/s \n",
            "\u001b[?25hCollecting pbr!=2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/e0/1d4702dd81121d04a477c272d47ee5b6bc970d1a0990b11befa275c55cf2/pbr-5.6.0-py2.py3-none-any.whl (111kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 37.4MB/s \n",
            "\u001b[?25hCollecting python-editor>=0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/c6/d3/201fc3abe391bbae6606e6f1d598c15d367033332bd54352b12f35513717/python_editor-1.0.4-py3-none-any.whl\n",
            "Collecting Mako\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/54/dbc07fbb20865d3b78fdb7cf7fa713e2cba4f87f71100074ef2dc9f9d1f7/Mako-1.1.4-py2.py3-none-any.whl (75kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 5.6MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.32->resampy>=0.2.2->deepspeech-training==0.10.0a3) (57.0.0)\n",
            "Requirement already satisfied, skipping upgrade: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.32->resampy>=0.2.2->deepspeech-training==0.10.0a3) (0.34.0)\n",
            "Requirement already satisfied, skipping upgrade: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile->deepspeech-training==0.10.0a3) (2.20)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.4->deepspeech-training==0.10.0a3) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.4->deepspeech-training==0.10.0a3) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.4->deepspeech-training==0.10.0a3) (3.3.4)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->sqlalchemy>=1.1.0->optuna->deepspeech-training==0.10.0a3) (3.4.1)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->sqlalchemy>=1.1.0->optuna->deepspeech-training==0.10.0a3) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna->deepspeech-training==0.10.0a3) (21.2.0)\n",
            "Requirement already satisfied, skipping upgrade: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna->deepspeech-training==0.10.0a3) (0.2.5)\n",
            "Collecting colorama>=0.3.7\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading https://files.pythonhosted.org/packages/a7/2c/4c64579f847bd5d539803c8b909e54ba087a79d01bb3aba433a95879a6c5/pyperclip-1.8.2.tar.gz\n",
            "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna->deepspeech-training==0.10.0a3) (2.0.1)\n",
            "Requirement already satisfied, skipping upgrade: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow==1.15.4->deepspeech-training==0.10.0a3) (1.5.2)\n",
            "Building wheels for collected packages: opuslib, pyogg, gast, pyperclip\n",
            "  Building wheel for opuslib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for opuslib: filename=opuslib-2.0.0-cp37-none-any.whl size=11011 sha256=0e7908a90a5f46d8a0bbd9d7e80cad099c50e2ac124da5aee46de287bd79b076\n",
            "  Stored in directory: /root/.cache/pip/wheels/a2/6e/92/421e586c65ec15713ba6da6c22e4f09e84d37ee14df6272ee3\n",
            "  Building wheel for pyogg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyogg: filename=PyOgg-0.6.14a1-py2.py3-none-any.whl size=35330 sha256=55486bf6c9ffe48ba2854cc6ec95b16cefc61196307435397709107682b2ee3e\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/90/9c/3ecc69e67664ae5bbd547f0843b47040f26f7ca9f9271f6db3\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp37-none-any.whl size=7557 sha256=42ecc31881af42af88b7bfc1d06a08258c1077587833416730a6828037c48725\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-cp37-none-any.whl size=11136 sha256=3d9d5cdb12f21a7fd4663477ea379a44d29deea1e619e242696739c90aafba7f\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/af/b8/3407109267803f4015e1ee2ff23be0c8c19ce4008665931ee1\n",
            "Successfully built opuslib pyogg gast pyperclip\n",
            "\u001b[31mERROR: tensorflow 1.15.4 has requirement numpy<1.19.0,>=1.16.0, but you'll have numpy 1.19.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-probability 0.13.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: kapre 0.3.5 has requirement tensorflow>=2.0.0, but you'll have tensorflow 1.15.4 which is incompatible.\u001b[0m\n",
            "Installing collected packages: attrdict, cmaes, colorlog, colorama, pyperclip, cmd2, pbr, stevedore, cliff, python-editor, Mako, alembic, optuna, opuslib, pyogg, pyxdg, sox, ds-ctcdecoder, keras-applications, tensorflow-estimator, gast, tensorboard, tensorflow, deepspeech-training\n",
            "  Found existing installation: tensorflow-estimator 2.5.0\n",
            "    Uninstalling tensorflow-estimator-2.5.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.5.0\n",
            "  Found existing installation: gast 0.4.0\n",
            "    Uninstalling gast-0.4.0:\n",
            "      Successfully uninstalled gast-0.4.0\n",
            "  Found existing installation: tensorboard 2.5.0\n",
            "    Uninstalling tensorboard-2.5.0:\n",
            "      Successfully uninstalled tensorboard-2.5.0\n",
            "  Found existing installation: tensorflow 2.5.0\n",
            "    Uninstalling tensorflow-2.5.0:\n",
            "      Successfully uninstalled tensorflow-2.5.0\n",
            "  Running setup.py develop for deepspeech-training\n",
            "Successfully installed Mako-1.1.4 alembic-1.6.5 attrdict-2.0.1 cliff-3.8.0 cmaes-0.8.2 cmd2-2.1.2 colorama-0.4.4 colorlog-5.0.1 deepspeech-training ds-ctcdecoder-0.10.0a3 gast-0.2.2 keras-applications-1.0.8 optuna-2.8.0 opuslib-2.0.0 pbr-5.6.0 pyogg-0.6.14a1 pyperclip-1.8.2 python-editor-1.0.4 pyxdg-0.27 sox-1.4.1 stevedore-3.3.0 tensorboard-1.15.0 tensorflow-1.15.4 tensorflow-estimator-1.15.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3i9nnM8hxEt",
        "outputId": "c72f62a0-6590-4c30-bab1-06b6045d8a90"
      },
      "source": [
        "!sudo apt-get install python3-dev"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "python3-dev is already the newest version (3.6.7-1~18.04).\n",
            "python3-dev set to manually installed.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KXzcOG6Fh0X4",
        "outputId": "cfdc44f4-db8f-4aa1-fda1-09fbd6863ab1"
      },
      "source": [
        "!pip3 uninstall tensorflow\n",
        "!pip3 install 'tensorflow-gpu==1.15.4'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling tensorflow-1.15.4:\n",
            "  Would remove:\n",
            "    /usr/local/bin/estimator_ckpt_converter\n",
            "    /usr/local/bin/freeze_graph\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow-1.15.4.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow/*\n",
            "    /usr/local/lib/python3.7/dist-packages/tensorflow_core/*\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled tensorflow-1.15.4\n",
            "Collecting tensorflow-gpu==1.15.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5f/37/cc3e7e5075552e985ef4b646e881446a7f5f0b470f780cc8ac6e502b43fa/tensorflow_gpu-1.15.4-cp37-cp37m-manylinux2010_x86_64.whl (411.0MB)\n",
            "\u001b[K     |████████████████████████████████| 411.0MB 41kB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.4) (1.15.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.4) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.4) (0.12.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.4) (3.3.0)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.4) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.4) (1.1.0)\n",
            "Collecting numpy<1.19.0,>=1.16.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d6/c6/58e517e8b1fb192725cfa23c01c2e60e4e6699314ee9684a1c5f5c9b27e1/numpy-1.18.5-cp37-cp37m-manylinux1_x86_64.whl (20.1MB)\n",
            "\u001b[K     |████████████████████████████████| 20.1MB 1.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.4) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.4) (1.1.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.4) (1.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.4) (1.12.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.4) (1.34.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.4) (3.17.3)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.4) (0.2.2)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.4) (0.36.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==1.15.4) (0.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.4) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.4) (57.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.4) (3.3.4)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==1.15.4) (3.1.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.4) (4.6.0)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow-gpu==1.15.4) (1.5.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.4) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.4) (3.4.1)\n",
            "\u001b[31mERROR: kapre 0.3.5 requires tensorflow>=2.0.0, which is not installed.\u001b[0m\n",
            "\u001b[31mERROR: deepspeech-training 0.10.0a3 requires tensorflow==1.15.4, which is not installed.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-probability 0.13.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: numpy, tensorflow-gpu\n",
            "  Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "Successfully installed numpy-1.18.5 tensorflow-gpu-1.15.4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4uSN9sWx3hY",
        "outputId": "ebaef399-2bc3-45a9-a4f1-7048e49f02e2"
      },
      "source": [
        "!pip install deepspeech"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting deepspeech\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/ca/5ac1f4b31f8b7721be20b692341fa6088c875e40f1cd0c0a27837b058f96/deepspeech-0.9.3-cp37-cp37m-manylinux1_x86_64.whl (9.2MB)\n",
            "\u001b[K     |████████████████████████████████| 9.2MB 3.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from deepspeech) (1.18.5)\n",
            "Installing collected packages: deepspeech\n",
            "Successfully installed deepspeech-0.9.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtYiRsH1iNi3",
        "outputId": "62b2b5cb-e0f1-433d-bbe5-7f566412dc27"
      },
      "source": [
        "%ls\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bazel.patch\n",
            "BIBLIOGRAPHY.md\n",
            "\u001b[0m\u001b[01;34mbin\u001b[0m/\n",
            "build-python-wheel.yml-DISABLED_ENABLE_ME_TO_REBUILD_DURING_PR\n",
            "\u001b[01;34mci_scripts\u001b[0m/\n",
            "CODE_OF_CONDUCT.md\n",
            "CODE_OWNERS.rst\n",
            "CONTRIBUTING.rst\n",
            "\u001b[01;34mdata\u001b[0m/\n",
            "\u001b[01;32mDeepSpeech.py\u001b[0m*\n",
            "\u001b[01;34mdoc\u001b[0m/\n",
            "Dockerfile.build.tmpl\n",
            "Dockerfile.train.tmpl\n",
            "ds_generic.supp\n",
            "ds_lib.supp\n",
            "ds_openfst.supp\n",
            "ds_sox.supp\n",
            "evaluate.py\n",
            "evaluate_tflite.py\n",
            "\u001b[01;34mexamples\u001b[0m/\n",
            "\u001b[01;36mGRAPH_VERSION\u001b[0m@\n",
            "\u001b[01;34mimages\u001b[0m/\n",
            "ISSUE_TEMPLATE.md\n",
            "\u001b[01;34mkenlm\u001b[0m/\n",
            "LICENSE\n",
            "lm_optimizer.py\n",
            "Makefile\n",
            "\u001b[01;34mnative_client\u001b[0m/\n",
            "\u001b[01;32mparse_valgrind_suppressions.sh\u001b[0m*\n",
            "README.rst\n",
            "RELEASE.rst\n",
            "requirements_eval_tflite.txt\n",
            "requirements_tests.txt\n",
            "requirements_transcribe.txt\n",
            "setup.py\n",
            "stats.py\n",
            "SUPPORT.rst\n",
            "\u001b[01;34mtaskcluster\u001b[0m/\n",
            "taskcluster.disabled.yml\n",
            "\u001b[01;34mtensorflow\u001b[0m/\n",
            "tensorflow_full_runtime.supp\n",
            "tensorflow_tflite_runtime.supp\n",
            "\u001b[01;34mtests\u001b[0m/\n",
            "\u001b[01;34mtraining\u001b[0m/\n",
            "\u001b[01;32mtranscribe.py\u001b[0m*\n",
            "\u001b[01;36mVERSION\u001b[0m@\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "id": "j7TWVuGVNI9F",
        "outputId": "b21f752a-b46d-44d1-a6c3-cb9d7f962db8"
      },
      "source": [
        "python3 generate_lm.py   --input_txt ../../../drive/MyDrive/deep/bangla.txt   --output_dir ../../../drive/MyDrive/deep/scorer   --top_k 500000 --kenlm_bins ../../kenlm/build/bin/   --arpa_order 5 --max_arpa_memory \"85%\" --arpa_prune \"0|0|1\"   --binary_a_bits 255 --binary_q_bits 8 --binary_type trie"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-17-fb0dbff42148>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    python3 generate_lm.py   --input_txt ../../../drive/MyDrive/deep/bangla.txt   --output_dir ../../../drive/MyDrive/deep/scorer   --top_k 500000 --kenlm_bins ../../native_client/kenlm/build/bin/   --arpa_order 5 --max_arpa_memory \"85%\" --arpa_prune \"0|0|1\"   --binary_a_bits 255 --binary_q_bits 8 --binary_type trie\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_WGku0o_Rjg",
        "outputId": "5327831f-4c42-44aa-8ae9-26eda26ca4a4"
      },
      "source": [
        "./generate_scorer_package \\\n",
        "  --alphabet ../../../drive/MyDrive/deep/alphabet.txt  \\\n",
        "  --lm ../../../drive/MyDrive/deep/scorer/lm.binary \\\n",
        "  --vocab ../../../drive/MyDrive/deep/scorer/vocab-500000.txt \\\n",
        "  --package bd.scorer \\\n",
        "  --default_alpha 0.931289039105002 \\\n",
        "  --default_beta 1.1834137581510284 \\\n",
        "  --force_bytes_output_mode True"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "\r100     9  100     9    0     0     46      0 --:--:-- --:--:-- --:--:--    46\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqHOF_4iuFdv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d572346-5432-4712-88c7-42f3dfc2d0e2"
      },
      "source": [
        "!python3 DeepSpeech.py \\\n",
        "--alphabet_config_path ../drive/MyDrive/Data1/alphabet.txt \\\n",
        "  --train_files ../drive/MyDrive/Data1/train/train.csv \\\n",
        "  --dev_files ../drive/MyDrive/Data1/dev/dev.csv \\\n",
        "  --test_files ../drive/MyDrive/Data1/test/test.csv \\\n",
        "  --checkpoint_dir ../drive/Shareddrives/SynthiaSoft.com-Unlimited-03/Data_for_Atik/train512/checkpoints_demo \\\n",
        "  --export_dir ../drive/MyDrive/Data1/exported-model \\\n",
        "  --load_checkpoint_dir ../drive/Shareddrives/SynthiaSoft.com-Unlimited-03/Data_for_Atik/train512/checkpoints_demo \\\n",
        "  --save_checkpoint_dir ../drive/Shareddrives/SynthiaSoft.com-Unlimited-03/Data_for_Atik/train512/checkpoints_demo \\\n",
        "  --checkpoint_secs 1800 \\\n",
        "  --max_to_keep 2 \\\n",
        "  --n_hidden 64 \\\n",
        "  --early_stop true \\\n",
        "  --es_epochs 10 \\\n",
        "  --use_allow_growth true \\\n",
        "  \n",
        "\n",
        "\n",
        "  \n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I0714 13:39:29.500261 140087486388096 utils.py:157] NumExpr defaulting to 2 threads.\n",
            "I Loading best validating checkpoint from ../drive/Shareddrives/SynthiaSoft.com-Unlimited-03/Data_for_Atik/train512/checkpoints_demo/best_dev-468643\n",
            "I Loading variable from checkpoint: beta1_power\n",
            "I Loading variable from checkpoint: beta2_power\n",
            "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias\n",
            "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias/Adam\n",
            "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias/Adam_1\n",
            "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel\n",
            "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel/Adam\n",
            "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel/Adam_1\n",
            "I Loading variable from checkpoint: global_step\n",
            "I Loading variable from checkpoint: layer_1/bias\n",
            "I Loading variable from checkpoint: layer_1/bias/Adam\n",
            "I Loading variable from checkpoint: layer_1/bias/Adam_1\n",
            "I Loading variable from checkpoint: layer_1/weights\n",
            "I Loading variable from checkpoint: layer_1/weights/Adam\n",
            "I Loading variable from checkpoint: layer_1/weights/Adam_1\n",
            "I Loading variable from checkpoint: layer_2/bias\n",
            "I Loading variable from checkpoint: layer_2/bias/Adam\n",
            "I Loading variable from checkpoint: layer_2/bias/Adam_1\n",
            "I Loading variable from checkpoint: layer_2/weights\n",
            "I Loading variable from checkpoint: layer_2/weights/Adam\n",
            "I Loading variable from checkpoint: layer_2/weights/Adam_1\n",
            "I Loading variable from checkpoint: layer_3/bias\n",
            "I Loading variable from checkpoint: layer_3/bias/Adam\n",
            "I Loading variable from checkpoint: layer_3/bias/Adam_1\n",
            "I Loading variable from checkpoint: layer_3/weights\n",
            "I Loading variable from checkpoint: layer_3/weights/Adam\n",
            "I Loading variable from checkpoint: layer_3/weights/Adam_1\n",
            "I Loading variable from checkpoint: layer_5/bias\n",
            "I Loading variable from checkpoint: layer_5/bias/Adam\n",
            "I Loading variable from checkpoint: layer_5/bias/Adam_1\n",
            "I Loading variable from checkpoint: layer_5/weights\n",
            "I Loading variable from checkpoint: layer_5/weights/Adam\n",
            "I Loading variable from checkpoint: layer_5/weights/Adam_1\n",
            "I Loading variable from checkpoint: layer_6/bias\n",
            "I Loading variable from checkpoint: layer_6/bias/Adam\n",
            "I Loading variable from checkpoint: layer_6/bias/Adam_1\n",
            "I Loading variable from checkpoint: layer_6/weights\n",
            "I Loading variable from checkpoint: layer_6/weights/Adam\n",
            "I Loading variable from checkpoint: layer_6/weights/Adam_1\n",
            "I Loading variable from checkpoint: learning_rate\n",
            "I STARTING Optimization\n",
            "Epoch 0 |   Training | Elapsed Time: 0:27:08 | Steps: 8532 | Loss: 37.534209    \n",
            "Epoch 0 | Validation | Elapsed Time: 0:08:36 | Steps: 2572 | Loss: 36.464543 | Dataset: ../drive/MyDrive/Data1/dev/dev.csv\n",
            "I Saved new best validating model with loss 36.464543 to: ../drive/Shareddrives/SynthiaSoft.com-Unlimited-03/Data_for_Atik/train512/checkpoints_demo/best_dev-477175\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 1 |   Training | Elapsed Time: 0:07:17 | Steps: 8532 | Loss: 37.635252    \n",
            "Epoch 1 | Validation | Elapsed Time: 0:02:09 | Steps: 2572 | Loss: 36.897135 | Dataset: ../drive/MyDrive/Data1/dev/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 2 |   Training | Elapsed Time: 0:07:15 | Steps: 8532 | Loss: 37.706072    \n",
            "Epoch 2 | Validation | Elapsed Time: 0:02:09 | Steps: 2572 | Loss: 36.715616 | Dataset: ../drive/MyDrive/Data1/dev/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 3 |   Training | Elapsed Time: 0:07:14 | Steps: 8532 | Loss: 37.578248    \n",
            "Epoch 3 | Validation | Elapsed Time: 0:02:09 | Steps: 2572 | Loss: 36.672382 | Dataset: ../drive/MyDrive/Data1/dev/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 4 |   Training | Elapsed Time: 0:07:14 | Steps: 8532 | Loss: 37.425989    \n",
            "Epoch 4 | Validation | Elapsed Time: 0:02:09 | Steps: 2572 | Loss: 36.978351 | Dataset: ../drive/MyDrive/Data1/dev/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 5 |   Training | Elapsed Time: 0:07:15 | Steps: 8532 | Loss: 37.579439    \n",
            "Epoch 5 | Validation | Elapsed Time: 0:02:09 | Steps: 2572 | Loss: 37.087403 | Dataset: ../drive/MyDrive/Data1/dev/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 6 |   Training | Elapsed Time: 0:07:15 | Steps: 8532 | Loss: 37.578528    \n",
            "Epoch 6 | Validation | Elapsed Time: 0:02:09 | Steps: 2572 | Loss: 36.389388 | Dataset: ../drive/MyDrive/Data1/dev/dev.csv\n",
            "I Saved new best validating model with loss 36.389388 to: ../drive/Shareddrives/SynthiaSoft.com-Unlimited-03/Data_for_Atik/train512/checkpoints_demo/best_dev-528367\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 7 |   Training | Elapsed Time: 0:07:14 | Steps: 8532 | Loss: 37.535194    \n",
            "Epoch 7 | Validation | Elapsed Time: 0:02:09 | Steps: 2572 | Loss: 36.890912 | Dataset: ../drive/MyDrive/Data1/dev/dev.csv\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 8 |   Training | Elapsed Time: 0:06:55 | Steps: 8256 | Loss: 35.748174    Process ForkPoolWorker-33:\n",
            "Process ForkPoolWorker-34:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
            "    task = get()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
            "    with self._rlock:\n",
            "  File \"/usr/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "KeyboardInterrupt\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
            "    task = get()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 352, in get\n",
            "    res = self._reader.recv_bytes()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 216, in recv_bytes\n",
            "    buf = self._recv_bytes(maxlength)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
            "    buf = self._recv(4)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
            "    chunk = read(handle, remaining)\n",
            "KeyboardInterrupt\n",
            "I FINISHED optimization in 1:48:38.359459\n",
            "I Loading best validating checkpoint from ../drive/Shareddrives/SynthiaSoft.com-Unlimited-03/Data_for_Atik/train512/checkpoints_demo/best_dev-528367\n",
            "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias\n",
            "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel\n",
            "I Loading variable from checkpoint: global_step\n",
            "I Loading variable from checkpoint: layer_1/bias\n",
            "I Loading variable from checkpoint: layer_1/weights\n",
            "I Loading variable from checkpoint: layer_2/bias\n",
            "I Loading variable from checkpoint: layer_2/weights\n",
            "I Loading variable from checkpoint: layer_3/bias\n",
            "I Loading variable from checkpoint: layer_3/weights\n",
            "I Loading variable from checkpoint: layer_5/bias\n",
            "I Loading variable from checkpoint: layer_5/weights\n",
            "I Loading variable from checkpoint: layer_6/bias\n",
            "I Loading variable from checkpoint: layer_6/weights\n",
            "Testing model on ../drive/MyDrive/Data1/test/test.csv\n",
            "Test epoch | Steps: 847 | Elapsed Time: 2:50:52                                 \n",
            "Test on ../drive/MyDrive/Data1/test/test.csv - WER: 1.000000, CER: 0.541073, loss: 36.197941\n",
            "--------------------------------------------------------------------------------\n",
            "Best WER: \n",
            "--------------------------------------------------------------------------------\n",
            "WER: 0.500000, CER: 0.461538, loss: 22.961859\n",
            " - wav: file://../drive/MyDrive/Data1/test/19abd7d3f6.wav\n",
            " - src: \"গ্রেফতার করার\"\n",
            " - res: \"সোন করার\"\n",
            "--------------------------------------------------------------------------------\n",
            "WER: 0.500000, CER: 0.363636, loss: 21.244581\n",
            " - wav: file://../drive/MyDrive/Data1/test/193522cce0.wav\n",
            " - src: \"ইসলামের কথা\"\n",
            " - res: \"সমানে কথা\"\n",
            "--------------------------------------------------------------------------------\n",
            "WER: 0.500000, CER: 0.454545, loss: 20.119032\n",
            " - wav: file://../drive/MyDrive/Data1/test/1948be56b7.wav\n",
            " - src: \"বেইজিং থেকে\"\n",
            " - res: \"সিমিন থেকে\"\n",
            "--------------------------------------------------------------------------------\n",
            "WER: 0.500000, CER: 0.307692, loss: 17.933117\n",
            " - wav: file://../drive/MyDrive/Data1/test/19dc191b1a.wav\n",
            " - src: \"সহযোগিতা করবে\"\n",
            " - res: \"সমজনিতা করবে\"\n",
            "--------------------------------------------------------------------------------\n",
            "WER: 0.500000, CER: 0.444444, loss: 14.095454\n",
            " - wav: file://../drive/MyDrive/Data1/test/19d25ec969.wav\n",
            " - src: \"দেওয়া হবে\"\n",
            " - res: \"বা হবে\"\n",
            "--------------------------------------------------------------------------------\n",
            "Median WER: \n",
            "--------------------------------------------------------------------------------\n",
            "WER: 1.000000, CER: 0.521739, loss: 30.930471\n",
            " - wav: file://../drive/MyDrive/Data1/test/19eaa06e20.wav\n",
            " - src: \"প্রচার অভিযান শেষ হয়েছে\"\n",
            " - res: \"সচার বেজান সেশ ছে\"\n",
            "--------------------------------------------------------------------------------\n",
            "WER: 1.000000, CER: 0.733333, loss: 30.914415\n",
            " - wav: file://../drive/MyDrive/Data1/test/191e2325b2.wav\n",
            " - src: \"গামছা দিয়ে ঝেড়ে\"\n",
            " - res: \"সাং্চাদি জি\"\n",
            "--------------------------------------------------------------------------------\n",
            "WER: 1.000000, CER: 0.500000, loss: 30.901613\n",
            " - wav: file://../drive/MyDrive/Data1/test/1903a3b1d9.wav\n",
            " - src: \"পঞ্চাশ হাজার টাকায়\"\n",
            " - res: \"সন্জাসাদা পাকায়\"\n",
            "--------------------------------------------------------------------------------\n",
            "WER: 1.000000, CER: 0.571429, loss: 30.809908\n",
            " - wav: file://../drive/MyDrive/Data1/test/19878fef10.wav\n",
            " - src: \"কেউ কেউ সরাসরি\"\n",
            " - res: \"সব সরসরি\"\n",
            "--------------------------------------------------------------------------------\n",
            "WER: 1.000000, CER: 0.714286, loss: 30.735704\n",
            " - wav: file://../drive/MyDrive/Data1/test/193478a23d.wav\n",
            " - src: \"ব্যাপক ব্যবহার\"\n",
            " - res: \"সাত মাবা\"\n",
            "--------------------------------------------------------------------------------\n",
            "Worst WER: \n",
            "--------------------------------------------------------------------------------\n",
            "WER: 2.000000, CER: 0.500000, loss: 13.135251\n",
            " - wav: file://../drive/MyDrive/Data1/test/19f9e9d8ec.wav\n",
            " - src: \"মহাদেব\"\n",
            " - res: \"স হাদে\"\n",
            "--------------------------------------------------------------------------------\n",
            "WER: 2.000000, CER: 0.666667, loss: 11.949556\n",
            " - wav: file://../drive/MyDrive/Data1/test/194b8af717.wav\n",
            " - src: \"কর্পূর\"\n",
            " - res: \"সর প\"\n",
            "--------------------------------------------------------------------------------\n",
            "WER: 2.500000, CER: 0.666667, loss: 43.491108\n",
            " - wav: file://../drive/MyDrive/Data1/test/19ed39b081.wav\n",
            " - src: \"খুবই উত্তেজনাপূর্ণ\"\n",
            " - res: \"স হবি হক্ত জরা ফি্ন\"\n",
            "--------------------------------------------------------------------------------\n",
            "WER: 2.500000, CER: 0.625000, loss: 31.219139\n",
            " - wav: file://../drive/MyDrive/Data1/test/19f00a1fa8.wav\n",
            " - src: \"টিআইবিকে ধন্যবাদ\"\n",
            " - res: \"সই আ বি তে হল্দবা\"\n",
            "--------------------------------------------------------------------------------\n",
            "WER: 3.000000, CER: 0.760000, loss: 58.622726\n",
            " - wav: file://../drive/MyDrive/Data1/test/1912d47bd4.wav\n",
            " - src: \"ভ্যালিন্টিন ন্যালিভাচেংকো\"\n",
            " - res: \"সাই তি নায়ে ভাচি ন ক\"\n",
            "--------------------------------------------------------------------------------\n",
            "I Exporting the model...\n",
            "I Loading best validating checkpoint from ../drive/Shareddrives/SynthiaSoft.com-Unlimited-03/Data_for_Atik/train512/checkpoints_demo/best_dev-528367\n",
            "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias\n",
            "I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel\n",
            "I Loading variable from checkpoint: layer_1/bias\n",
            "I Loading variable from checkpoint: layer_1/weights\n",
            "I Loading variable from checkpoint: layer_2/bias\n",
            "I Loading variable from checkpoint: layer_2/weights\n",
            "I Loading variable from checkpoint: layer_3/bias\n",
            "I Loading variable from checkpoint: layer_3/weights\n",
            "I Loading variable from checkpoint: layer_5/bias\n",
            "I Loading variable from checkpoint: layer_5/weights\n",
            "I Loading variable from checkpoint: layer_6/bias\n",
            "I Loading variable from checkpoint: layer_6/weights\n",
            "I Models exported at ../drive/MyDrive/Data1/exported-model\n",
            "I Model metadata file saved to ../drive/MyDrive/Data1/exported-model/author_model_0.0.1.md. Before submitting the exported model for publishing make sure all information in the metadata file is correct, and complete the URL fields.\n",
            "Error in atexit._run_exitfuncs:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/util.py\", line 300, in _run_finalizers\n",
            "    finalizer()\n",
            "Process ForkPoolWorker-35:\n",
            "  File \"/usr/lib/python3.7/multiprocessing/util.py\", line 224, in __call__\n",
            "    res = self._callback(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 581, in _terminate_pool\n",
            "    cls._help_stuff_finish(inqueue, task_handler, len(pool))\n",
            "Process ForkPoolWorker-36:\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 566, in _help_stuff_finish\n",
            "    inqueue._rlock.acquire()\n",
            "KeyboardInterrupt\n",
            "\u001b[0mTraceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
            "    task = get()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
            "    with self._rlock:\n",
            "  File \"/usr/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "KeyboardInterrupt\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
            "    task = get()\n",
            "  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
            "    with self._rlock:\n",
            "  File \"/usr/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOymLETvtlNN",
        "outputId": "543e0c55-4556-43d3-c41e-3a551fe3f209"
      },
      "source": [
        "!apt -qq install -y sox"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The following additional packages will be installed:\n",
            "  libmagic-mgc libmagic1 libopencore-amrnb0 libopencore-amrwb0 libsox-fmt-alsa\n",
            "  libsox-fmt-base libsox3\n",
            "Suggested packages:\n",
            "  file libsox-fmt-all\n",
            "The following NEW packages will be installed:\n",
            "  libmagic-mgc libmagic1 libopencore-amrnb0 libopencore-amrwb0 libsox-fmt-alsa\n",
            "  libsox-fmt-base libsox3 sox\n",
            "0 upgraded, 8 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 760 kB of archives.\n",
            "After this operation, 6,717 kB of additional disk space will be used.\n",
            "Selecting previously unselected package libopencore-amrnb0:amd64.\n",
            "(Reading database ... 160772 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libopencore-amrnb0_0.1.3-2.1_amd64.deb ...\n",
            "Unpacking libopencore-amrnb0:amd64 (0.1.3-2.1) ...\n",
            "Selecting previously unselected package libopencore-amrwb0:amd64.\n",
            "Preparing to unpack .../1-libopencore-amrwb0_0.1.3-2.1_amd64.deb ...\n",
            "Unpacking libopencore-amrwb0:amd64 (0.1.3-2.1) ...\n",
            "Selecting previously unselected package libmagic-mgc.\n",
            "Preparing to unpack .../2-libmagic-mgc_1%3a5.32-2ubuntu0.4_amd64.deb ...\n",
            "Unpacking libmagic-mgc (1:5.32-2ubuntu0.4) ...\n",
            "Selecting previously unselected package libmagic1:amd64.\n",
            "Preparing to unpack .../3-libmagic1_1%3a5.32-2ubuntu0.4_amd64.deb ...\n",
            "Unpacking libmagic1:amd64 (1:5.32-2ubuntu0.4) ...\n",
            "Selecting previously unselected package libsox3:amd64.\n",
            "Preparing to unpack .../4-libsox3_14.4.2-3ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking libsox3:amd64 (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package libsox-fmt-alsa:amd64.\n",
            "Preparing to unpack .../5-libsox-fmt-alsa_14.4.2-3ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-alsa:amd64 (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package libsox-fmt-base:amd64.\n",
            "Preparing to unpack .../6-libsox-fmt-base_14.4.2-3ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking libsox-fmt-base:amd64 (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package sox.\n",
            "Preparing to unpack .../7-sox_14.4.2-3ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking sox (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Setting up libmagic-mgc (1:5.32-2ubuntu0.4) ...\n",
            "Setting up libmagic1:amd64 (1:5.32-2ubuntu0.4) ...\n",
            "Setting up libopencore-amrnb0:amd64 (0.1.3-2.1) ...\n",
            "Setting up libopencore-amrwb0:amd64 (0.1.3-2.1) ...\n",
            "Setting up libsox3:amd64 (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Setting up libsox-fmt-base:amd64 (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Setting up libsox-fmt-alsa:amd64 (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Setting up sox (14.4.2-3ubuntu0.18.04.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vod55GZ42ix-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdfddf81-ee17-41b4-bb80-0097baa58570"
      },
      "source": [
        "!deepspeech --model ../drive/Shareddrives/SynthiaSoft.com-Unlimited-03/Data_for_Atik/Data_for_Atik_4/exported_model/output_graph.pb --audio ../drive/Shareddrives/SynthiaSoft.com-Unlimited-03/195590bd5b.wav"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading model from file ../drive/Shareddrives/SynthiaSoft.com-Unlimited-03/Data_for_Atik/Data_for_Atik_4/exported_model/output_graph.pb\n",
            "TensorFlow: v2.3.0-6-g23ad988\n",
            "DeepSpeech: v0.9.3-0-gf2e9c85\n",
            "Warning: reading entire model file into memory. Transform model file into an mmapped graph to reduce heap usage.\n",
            "2021-07-07 06:21:53.869176: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Loaded model in 0.0278s.\n",
            "Running inference.\n",
            "সনে বামে সুতা\n",
            "Inference took 3.087s for 2.400s audio file.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}